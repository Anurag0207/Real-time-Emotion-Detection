{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTRgs2yHEnRL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/your_dataset_directory'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxEh3OlCEszs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model,load_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,ELU ,Dense ,Conv2D ,Add ,Activation , Flatten, Dropout , GlobalAveragePooling2D, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D, AveragePooling2D, Subtract, Concatenate, ZeroPadding2D,Conv2DTranspose,SeparableConv2D\n",
        "import tensorflow as tf\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfTfMDWuFG37",
        "outputId": "d2642069-31e1-4843-b750-02053cce565a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Bkr0Ii8JKUOHGFq71NkzGuqJpoG1mYrD\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 101M/101M [00:01<00:00, 67.0MB/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "file_id = \"1Bkr0Ii8JKUOHGFq71NkzGuqJpoG1mYrD\"\n",
        "output_file = \"/content/dataset.zip\"\n",
        "\n",
        "import gdown\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file, quiet=False)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(output_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGQBd6nfFR9x"
      },
      "outputs": [],
      "source": [
        "def dataset():\n",
        "  df = pd.read_csv(\"/content/fer2013/fer2013/fer2013.csv\")\n",
        "  train_samples = df[df['Usage']==\"Training\"]\n",
        "  validation_samples = df[df['Usage']=='PublicTest']\n",
        "  test_samples=df[df[\"Usage\"]==\"PrivateTest\"]\n",
        "\n",
        "  y_train=keras.utils.to_categorical(train_samples.emotion, num_classes=7 )\n",
        "  y_valid=keras.utils.to_categorical(validation_samples.emotion, num_classes=7)\n",
        "  y_test=keras.utils.to_categorical(test_samples.emotion, num_classes=7)\n",
        "\n",
        "\n",
        "  x_train = np.array([np.fromstring(image, np.uint8, sep=\" \").reshape((48, 48)) for image in train_samples.pixels])\n",
        "  x_valid = np.array([np.fromstring(image, np.uint8, sep=\" \").reshape((48, 48)) for image in validation_samples.pixels])\n",
        "  x_test = np.array([np.fromstring(image, np.uint8, sep=\" \").reshape((48, 48)) for image in test_samples.pixels])\n",
        "  return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
        "\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = dataset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "_-J29ipmFUUA",
        "outputId": "67518aba-6257-480f-f599-73aedbd32883"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/text.py:1279: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "first_image = x_train[0]\n",
        "plt.imshow(first_image, cmap='gray')\n",
        "plt.title(y_train[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG0izSI7JUN7"
      },
      "outputs": [],
      "source": [
        "def model(lr=0.001):\n",
        "  input=Input(shape=(48,48,1))\n",
        "  block1_layer11=SeparableConv2D(32,(3,3), padding=\"valid\",data_format='channels_last',kernel_regularizer=regularizers.l2(0.00001),name='block1_sep_conv1')(input)\n",
        "  block1_layer1=Activation('relu',name='block1_relu1')(block1_layer11)\n",
        "  block1_layer1=BatchNormalization(name='block1_batch1')(block1_layer1)\n",
        "  block1_layer1=Dropout(0.1,name='block1_drop1')(block1_layer1)\n",
        "  block1_layer2=SeparableConv2D(32,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block1_sep_conv2')(block1_layer1)\n",
        "  block1_layer2=Activation('relu',name='block1_relu2')(block1_layer2)\n",
        "  block1_layer2=BatchNormalization(name='block1_batch2')(block1_layer2)\n",
        "  block1_layer2=Dropout(0.1,name='block1_drop2')(block1_layer2)\n",
        "  block1_layer3=SeparableConv2D(32,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block1_sep_conv3')(block1_layer2)\n",
        "  block1_add1=Add(name='block1_add')([block1_layer3,block1_layer11])\n",
        "  block1_layer3=Activation('relu',name='block1_relu')(block1_add1)\n",
        "  block1_layer3=BatchNormalization(name='block1_batch3')(block1_layer3)\n",
        "  block1_layer3=ZeroPadding2D((3,3),name='block1_zeroo')(block1_layer3)\n",
        "  block1_layer3=AveragePooling2D(name='block1_avg')(block1_layer3)\n",
        "  block1_layer3=Dropout(0.1,name='block1_drop3')(block1_layer3)\n",
        "  block2_layer11=SeparableConv2D(64,(3,3), padding='valid',kernel_regularizer=regularizers.l2(0.00001),name='block2_sep_conv1')(block1_layer3)\n",
        "  block2_layer1=Activation('relu',name='block2_relu1')(block2_layer11)\n",
        "  block2_layer1=BatchNormalization(name='block2_batch1')(block2_layer1)\n",
        "  block2_layer1=Dropout(0.2,name='block2_drop1')(block2_layer1)\n",
        "  block2_layer2=SeparableConv2D(64,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block2_sep_conv2')(block2_layer1)\n",
        "  block2_layer2=Activation('relu',name='block2_relu2')(block2_layer2)\n",
        "  block2_layer2=BatchNormalization(name='block2_batch2')(block2_layer2)\n",
        "  block2_layer2=Dropout(0.2,name='block2_drop2')(block2_layer2)\n",
        "  block2_layer3=SeparableConv2D(64,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block2_sep_conv3')(block2_layer2)\n",
        "  block2_add1=Add(name='block2_add')([block2_layer3,block2_layer11])\n",
        "  block2_layer3=Activation('relu',name='block2_relu')(block2_add1)\n",
        "  block2_layer3=BatchNormalization(name='block2_batch3')(block2_layer3)\n",
        "  block2_layer3=ZeroPadding2D((3,3),name='block2_zeroo')(block2_layer3)\n",
        "  block2_layer3=AveragePooling2D(name='block2_avg')(block2_layer3)\n",
        "  block2_layer3=Dropout(0.2,name='block2_drop3')(block2_layer3)\n",
        "  block3_layer11=SeparableConv2D(96,(3,3), padding='valid',kernel_regularizer=regularizers.l2(0.00001),name='block3_sep_conv1')(block2_layer3)\n",
        "  block3_layer1=Activation('relu',name='block3_relu1')(block3_layer11)\n",
        "  block3_layer1=BatchNormalization(name='block3_batch1')(block3_layer1)\n",
        "  block3_layer1=Dropout(0.25,name='block3_drop1')(block3_layer1)\n",
        "  block3_layer2=SeparableConv2D(96,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block3_sep_conv2')(block3_layer1)\n",
        "  block3_layer2=Activation('relu',name='block3_relu2')(block3_layer2)\n",
        "  block3_layer2=BatchNormalization(name='block3_batch2')(block3_layer2)\n",
        "  block3_layer2=Dropout(0.25,name='block3_drop2')(block3_layer2)\n",
        "  block3_layer3=SeparableConv2D(96,(3,3), padding='same',kernel_regularizer=regularizers.l2(0.00001),name='block3_sep_conv3')(block3_layer2)\n",
        "  block3_add1=Add(name='block3_add')([block3_layer3,block3_layer11])\n",
        "  block3_layer3=Activation('relu',name='block3_relu')(block3_add1)\n",
        "  block3_layer3=BatchNormalization(name='block3_batch3')(block3_layer3)\n",
        "  block3_layer3=ZeroPadding2D((3,3),name='block3_zeroo')(block3_layer3)\n",
        "  block3_layer3=AveragePooling2D(name='block3_avg')(block3_layer3)\n",
        "  block3_layer3=Dropout(0.25,name='block3_drop3')(block3_layer3)\n",
        "  Global_Pooling=GlobalMaxPooling2D(name='Global_Pooling')(block3_layer3)\n",
        "  Drop_Global_Pooling=Dropout(0.25,name='dense_drop1')(Global_Pooling)\n",
        "  Dens1=Dense(96,activation='relu',name='dense1')(Drop_Global_Pooling)\n",
        "  Dens1=BatchNormalization(name='dense_batch')(Dens1)\n",
        "  Drop_Dens1=Dropout(0.25,name='dense_drop2')(Dens1)\n",
        "\n",
        "  Softmax_=Dense(7,activation='softmax',name='softmax')(Drop_Dens1)\n",
        "  model=Model(input, Softmax_)\n",
        "  model.summary()\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.001) , metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF7d1UsnMhCI",
        "outputId": "a2fad877-40a9-41f5-defe-ce522dbb80c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " block1_sep_conv1 (Separabl  (None, 46, 46, 32)           73        ['input_1[0][0]']             \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block1_relu1 (Activation)   (None, 46, 46, 32)           0         ['block1_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block1_batch1 (BatchNormal  (None, 46, 46, 32)           128       ['block1_relu1[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block1_drop1 (Dropout)      (None, 46, 46, 32)           0         ['block1_batch1[0][0]']       \n",
            "                                                                                                  \n",
            " block1_sep_conv2 (Separabl  (None, 46, 46, 32)           1344      ['block1_drop1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block1_relu2 (Activation)   (None, 46, 46, 32)           0         ['block1_sep_conv2[0][0]']    \n",
            "                                                                                                  \n",
            " block1_batch2 (BatchNormal  (None, 46, 46, 32)           128       ['block1_relu2[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block1_drop2 (Dropout)      (None, 46, 46, 32)           0         ['block1_batch2[0][0]']       \n",
            "                                                                                                  \n",
            " block1_sep_conv3 (Separabl  (None, 46, 46, 32)           1344      ['block1_drop2[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block1_add (Add)            (None, 46, 46, 32)           0         ['block1_sep_conv3[0][0]',    \n",
            "                                                                     'block1_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block1_relu (Activation)    (None, 46, 46, 32)           0         ['block1_add[0][0]']          \n",
            "                                                                                                  \n",
            " block1_batch3 (BatchNormal  (None, 46, 46, 32)           128       ['block1_relu[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block1_zeroo (ZeroPadding2  (None, 52, 52, 32)           0         ['block1_batch3[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block1_avg (AveragePooling  (None, 26, 26, 32)           0         ['block1_zeroo[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1_drop3 (Dropout)      (None, 26, 26, 32)           0         ['block1_avg[0][0]']          \n",
            "                                                                                                  \n",
            " block2_sep_conv1 (Separabl  (None, 24, 24, 64)           2400      ['block1_drop3[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block2_relu1 (Activation)   (None, 24, 24, 64)           0         ['block2_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block2_batch1 (BatchNormal  (None, 24, 24, 64)           256       ['block2_relu1[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2_drop1 (Dropout)      (None, 24, 24, 64)           0         ['block2_batch1[0][0]']       \n",
            "                                                                                                  \n",
            " block2_sep_conv2 (Separabl  (None, 24, 24, 64)           4736      ['block2_drop1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block2_relu2 (Activation)   (None, 24, 24, 64)           0         ['block2_sep_conv2[0][0]']    \n",
            "                                                                                                  \n",
            " block2_batch2 (BatchNormal  (None, 24, 24, 64)           256       ['block2_relu2[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2_drop2 (Dropout)      (None, 24, 24, 64)           0         ['block2_batch2[0][0]']       \n",
            "                                                                                                  \n",
            " block2_sep_conv3 (Separabl  (None, 24, 24, 64)           4736      ['block2_drop2[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block2_add (Add)            (None, 24, 24, 64)           0         ['block2_sep_conv3[0][0]',    \n",
            "                                                                     'block2_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block2_relu (Activation)    (None, 24, 24, 64)           0         ['block2_add[0][0]']          \n",
            "                                                                                                  \n",
            " block2_batch3 (BatchNormal  (None, 24, 24, 64)           256       ['block2_relu[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2_zeroo (ZeroPadding2  (None, 30, 30, 64)           0         ['block2_batch3[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2_avg (AveragePooling  (None, 15, 15, 64)           0         ['block2_zeroo[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_drop3 (Dropout)      (None, 15, 15, 64)           0         ['block2_avg[0][0]']          \n",
            "                                                                                                  \n",
            " block3_sep_conv1 (Separabl  (None, 13, 13, 96)           6816      ['block2_drop3[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block3_relu1 (Activation)   (None, 13, 13, 96)           0         ['block3_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block3_batch1 (BatchNormal  (None, 13, 13, 96)           384       ['block3_relu1[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3_drop1 (Dropout)      (None, 13, 13, 96)           0         ['block3_batch1[0][0]']       \n",
            "                                                                                                  \n",
            " block3_sep_conv2 (Separabl  (None, 13, 13, 96)           10176     ['block3_drop1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block3_relu2 (Activation)   (None, 13, 13, 96)           0         ['block3_sep_conv2[0][0]']    \n",
            "                                                                                                  \n",
            " block3_batch2 (BatchNormal  (None, 13, 13, 96)           384       ['block3_relu2[0][0]']        \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3_drop2 (Dropout)      (None, 13, 13, 96)           0         ['block3_batch2[0][0]']       \n",
            "                                                                                                  \n",
            " block3_sep_conv3 (Separabl  (None, 13, 13, 96)           10176     ['block3_drop2[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " block3_add (Add)            (None, 13, 13, 96)           0         ['block3_sep_conv3[0][0]',    \n",
            "                                                                     'block3_sep_conv1[0][0]']    \n",
            "                                                                                                  \n",
            " block3_relu (Activation)    (None, 13, 13, 96)           0         ['block3_add[0][0]']          \n",
            "                                                                                                  \n",
            " block3_batch3 (BatchNormal  (None, 13, 13, 96)           384       ['block3_relu[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3_zeroo (ZeroPadding2  (None, 19, 19, 96)           0         ['block3_batch3[0][0]']       \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3_avg (AveragePooling  (None, 9, 9, 96)             0         ['block3_zeroo[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_drop3 (Dropout)      (None, 9, 9, 96)             0         ['block3_avg[0][0]']          \n",
            "                                                                                                  \n",
            " Global_Pooling (GlobalMaxP  (None, 96)                   0         ['block3_drop3[0][0]']        \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " dense_drop1 (Dropout)       (None, 96)                   0         ['Global_Pooling[0][0]']      \n",
            "                                                                                                  \n",
            " dense1 (Dense)              (None, 96)                   9312      ['dense_drop1[0][0]']         \n",
            "                                                                                                  \n",
            " dense_batch (BatchNormaliz  (None, 96)                   384       ['dense1[0][0]']              \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " dense_drop2 (Dropout)       (None, 96)                   0         ['dense_batch[0][0]']         \n",
            "                                                                                                  \n",
            " softmax (Dense)             (None, 7)                    679       ['dense_drop2[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54480 (212.81 KB)\n",
            "Trainable params: 53136 (207.56 KB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model=model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urG8I1VaLXPr",
        "outputId": "b38e18d8-163e-4d71-a535-00b66026f068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-5d2cabb47d72>:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(aug.flow(np.array(x_train_std),np.array(y_train),batch_size=64),epochs=50,callbacks=callbacks_list,validation_data=(np.array(x_valid_std),np.array(y_valid)),steps_per_epoch=len(np.array(x_train_std))/64)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "449/448 [==============================] - ETA: 0s - loss: 2.0339 - accuracy: 0.2063\n",
            "Epoch 1: val_loss improved from inf to 1.83606, saving model to /content/drive/My Drive/weights.bestvgg.h5\n",
            "448/448 [==============================] - 392s 855ms/step - loss: 2.0339 - accuracy: 0.2063 - val_loss: 1.8361 - val_accuracy: 0.2494\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "449/448 [==============================] - ETA: 0s - loss: 1.8296 - accuracy: 0.2432\n",
            "Epoch 2: val_loss improved from 1.83606 to 1.80227, saving model to /content/drive/My Drive/weights.bestvgg.h5\n",
            "448/448 [==============================] - 374s 835ms/step - loss: 1.8296 - accuracy: 0.2432 - val_loss: 1.8023 - val_accuracy: 0.2491\n",
            "Epoch 3/50\n",
            "133/448 [=======>......................] - ETA: 4:21 - loss: 1.8000 - accuracy: 0.2586"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "\n",
        "    x_train, y_train, x_valid, y_valid, x_test, y_test =  dataset()\n",
        "\n",
        "    x_train = x_train.reshape((-1,48,48,1)).astype(np.float32)\n",
        "    x_valid = x_valid.reshape((-1,48,48,1)).astype(np.float32)\n",
        "    x_test = x_test.reshape((-1,48,48,1)).astype(np.float32)\n",
        "    filepath=\"/content/drive/My Drive/weights.bestvgg.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "    x_train_std = x_train/255.\n",
        "    x_valid_std = x_valid/255.\n",
        "    x_test_std = x_test/255.\n",
        "    aug = keras.preprocessing.image.ImageDataGenerator(rotation_range=0.25,width_shift_range=0.1,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode=\"nearest\")\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "         history = model.fit_generator(aug.flow(np.array(x_train_std),np.array(y_train),batch_size=64),epochs=50,callbacks=callbacks_list,validation_data=(np.array(x_valid_std),np.array(y_valid)),steps_per_epoch=len(np.array(x_train_std))/64)\n",
        "         loss_test, acc_test=model.evaluate(x_test_std,y_test)\n",
        "         print(loss_test, acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojFNMzbfRArZ"
      },
      "outputs": [],
      "source": [
        "model.save(\"emotion_detector.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrcQOi2yRC5M"
      },
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"emotion_detector.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"motion_detector_weights.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LANonbLga8Nz"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"motion_detector_weights.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUvts2d7basW"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "with open(\"emotion_detector.json\", \"r\") as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "loaded_model.load_weights(\"model_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA3WoXP6dYwh"
      },
      "outputs": [],
      "source": [
        "labels = ['angry','disgust','fear','happy','neutral','sad','surprise']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBsO40bwNbpb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsNvNPYTdnYQ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "def ef(image, label):\n",
        "    feature = np.array(image)\n",
        "    feature = feature.reshape(1, 48, 48, 1)\n",
        "    return feature / 255.0, label\n",
        "\n",
        "image = x_test[10]\n",
        "label = y_test[10]\n",
        "print(\"Original label:\", label)\n",
        "img, true_label = ef(image, label)\n",
        "pred = model.predict(img)\n",
        "pred_label = labels[pred.argmax()]\n",
        "print(\"Model prediction:\", pred_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PKpt-gjahCN-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 592ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# Load the pre-trained emotion detection model\n",
        "with open(\"emotion_detector.json\", \"r\") as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"motion_detector_weights.h5\")\n",
        "\n",
        "# Define the emotion labels\n",
        "emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# Initialize the webcam capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to grayscale and resize it to match the model input size (48x48)\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    resized_frame = cv2.resize(gray_frame, (48, 48))\n",
        "\n",
        "    # Normalize the frame\n",
        "    normalized_frame = resized_frame / 255.0\n",
        "\n",
        "    # Make a prediction using the loaded model\n",
        "    prediction = loaded_model.predict(normalized_frame.reshape(1, 48, 48, 1))\n",
        "\n",
        "    # Get the emotion label with the highest probability\n",
        "    emotion = emotion_labels[np.argmax(prediction)]\n",
        "\n",
        "    # Display the emotion on the frame\n",
        "    cv2.putText(frame, \"Emotion: \" + emotion, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Real-Time Emotion Detection', frame)\n",
        "\n",
        "    # Exit the loop when the 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the webcam and close all OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
